_target_: classifier.models.gpt_module.GPTLitModule

block_size : 4
learning_rate: 0.001

optimizer:
  _target_: torch.optim.Adam
  _partial_: true
  lr: 0.001
  weight_decay: 0.0

scheduler:
  _target_: torch.optim.lr_scheduler.ReduceLROnPlateau
  _partial_: true
  mode: min
  factor: 0.1
  patience: 10
  
net:
  _target_ : classifier.models.gpt_module.GPT
  vocab_size : 100277
  block_size : ${model.block_size}
  n_embed : 64
  n_decoder_blocks : 4
  decoder_block:
    _target_: classifier.models.gpt_module.GPTDecoderBlock
    emb_size: ${model.net.n_embed}
    drop_p: 0.1
    forward_expansion: 4
    forward_drop_p: 0
    n_heads: 4